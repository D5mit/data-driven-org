{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Driven Organisations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# import pandas module \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# import header file\n",
    "df_header = pd.read_excel('data/question_headers.xlsx')  #original\n",
    "df = pd.read_excel('data/output.xlsx')  #original\n",
    "# df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# df_header.iloc[1].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>resp_id</th>\n",
       "      <th>colle_id</th>\n",
       "      <th>email</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>custom_data</th>\n",
       "      <th>d_tools</th>\n",
       "      <th>d_capabilities</th>\n",
       "      <th>d_culture</th>\n",
       "      <th>...</th>\n",
       "      <th>sy_fairness_to_trust</th>\n",
       "      <th>sy_trust_to_adoption</th>\n",
       "      <th>sy_lack_trust_low_adoption</th>\n",
       "      <th>ai_transparency_to_trust</th>\n",
       "      <th>ai_accountability_to_trust</th>\n",
       "      <th>ai_fairness_to_trust</th>\n",
       "      <th>ai_trust_to_adoption</th>\n",
       "      <th>ai_lack_trust_low_adoption</th>\n",
       "      <th>ai_must_be_trans_expl</th>\n",
       "      <th>ai_fat_to_trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>138.000000</td>\n",
       "      <td>1.380000e+02</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>135.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>69.500000</td>\n",
       "      <td>1.288964e+10</td>\n",
       "      <td>404063954.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.231884</td>\n",
       "      <td>4.434783</td>\n",
       "      <td>4.362319</td>\n",
       "      <td>...</td>\n",
       "      <td>4.264706</td>\n",
       "      <td>4.551471</td>\n",
       "      <td>4.595588</td>\n",
       "      <td>4.081481</td>\n",
       "      <td>4.365672</td>\n",
       "      <td>4.185185</td>\n",
       "      <td>4.485075</td>\n",
       "      <td>4.562963</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>4.562963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39.981246</td>\n",
       "      <td>4.013827e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.856830</td>\n",
       "      <td>0.724509</td>\n",
       "      <td>0.782491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680254</td>\n",
       "      <td>0.581440</td>\n",
       "      <td>0.744149</td>\n",
       "      <td>0.970089</td>\n",
       "      <td>0.710195</td>\n",
       "      <td>0.848046</td>\n",
       "      <td>0.597426</td>\n",
       "      <td>0.593590</td>\n",
       "      <td>0.620544</td>\n",
       "      <td>0.580882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.288637e+10</td>\n",
       "      <td>404063954.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.250000</td>\n",
       "      <td>1.288657e+10</td>\n",
       "      <td>404063954.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>69.500000</td>\n",
       "      <td>1.288914e+10</td>\n",
       "      <td>404063954.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>103.750000</td>\n",
       "      <td>1.288939e+10</td>\n",
       "      <td>404063954.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>138.000000</td>\n",
       "      <td>1.289784e+10</td>\n",
       "      <td>404063954.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       resp_id     colle_id  email  first_name  last_name  \\\n",
       "count  138.000000  1.380000e+02        138.0    0.0         0.0        0.0   \n",
       "mean    69.500000  1.288964e+10  404063954.0    NaN         NaN        NaN   \n",
       "std     39.981246  4.013827e+06          0.0    NaN         NaN        NaN   \n",
       "min      1.000000  1.288637e+10  404063954.0    NaN         NaN        NaN   \n",
       "25%     35.250000  1.288657e+10  404063954.0    NaN         NaN        NaN   \n",
       "50%     69.500000  1.288914e+10  404063954.0    NaN         NaN        NaN   \n",
       "75%    103.750000  1.288939e+10  404063954.0    NaN         NaN        NaN   \n",
       "max    138.000000  1.289784e+10  404063954.0    NaN         NaN        NaN   \n",
       "\n",
       "       custom_data     d_tools  d_capabilities   d_culture  ...  \\\n",
       "count          0.0  138.000000      138.000000  138.000000  ...   \n",
       "mean           NaN    4.231884        4.434783    4.362319  ...   \n",
       "std            NaN    0.856830        0.724509    0.782491  ...   \n",
       "min            NaN    1.000000        1.000000    1.000000  ...   \n",
       "25%            NaN    4.000000        4.000000    4.000000  ...   \n",
       "50%            NaN    4.000000        5.000000    4.000000  ...   \n",
       "75%            NaN    5.000000        5.000000    5.000000  ...   \n",
       "max            NaN    5.000000        5.000000    5.000000  ...   \n",
       "\n",
       "       sy_fairness_to_trust  sy_trust_to_adoption  sy_lack_trust_low_adoption  \\\n",
       "count            136.000000            136.000000                  136.000000   \n",
       "mean               4.264706              4.551471                    4.595588   \n",
       "std                0.680254              0.581440                    0.744149   \n",
       "min                2.000000              2.000000                    1.000000   \n",
       "25%                4.000000              4.000000                    4.000000   \n",
       "50%                4.000000              5.000000                    5.000000   \n",
       "75%                5.000000              5.000000                    5.000000   \n",
       "max                5.000000              5.000000                    5.000000   \n",
       "\n",
       "       ai_transparency_to_trust  ai_accountability_to_trust  \\\n",
       "count                135.000000                  134.000000   \n",
       "mean                   4.081481                    4.365672   \n",
       "std                    0.970089                    0.710195   \n",
       "min                    1.000000                    2.000000   \n",
       "25%                    4.000000                    4.000000   \n",
       "50%                    4.000000                    4.000000   \n",
       "75%                    5.000000                    5.000000   \n",
       "max                    5.000000                    5.000000   \n",
       "\n",
       "       ai_fairness_to_trust  ai_trust_to_adoption  ai_lack_trust_low_adoption  \\\n",
       "count            135.000000            134.000000                  135.000000   \n",
       "mean               4.185185              4.485075                    4.562963   \n",
       "std                0.848046              0.597426                    0.593590   \n",
       "min                1.000000              3.000000                    2.000000   \n",
       "25%                4.000000              4.000000                    4.000000   \n",
       "50%                4.000000              5.000000                    5.000000   \n",
       "75%                5.000000              5.000000                    5.000000   \n",
       "max                5.000000              5.000000                    5.000000   \n",
       "\n",
       "       ai_must_be_trans_expl  ai_fat_to_trust  \n",
       "count             135.000000       135.000000  \n",
       "mean                4.466667         4.562963  \n",
       "std                 0.620544         0.580882  \n",
       "min                 2.000000         2.000000  \n",
       "25%                 4.000000         4.000000  \n",
       "50%                 5.000000         5.000000  \n",
       "75%                 5.000000         5.000000  \n",
       "max                 5.000000         5.000000  \n",
       "\n",
       "[8 rows x 91 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI and Trust H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Metric</strong><br>\n",
    "The questionnaire provided importance measures in terms of the relationship between FAT and trust, trust and increased adoption and FAT and adoption.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/TOEFAT_H.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Objective H4</strong><br>\n",
    "Question: In the context of AI. From a product owner perspective, is trustworthiness an important contributor to the adoption of the system.\n",
    "Check if Trust is an important contributer towards the adoption of AI.\n",
    "<br>\n",
    "\n",
    "ai_trust_to_adoption = Extremely important and Very important<br>\n",
    "ai_trust_not_to_adoption = Somewhat important and Not so important and Not at all important\n",
    "\n",
    "<strong>Hypothesis</strong><br>\n",
    "H0: ai_trust_to_adoption - ai_trust_not_to_adoption = 0 <br>\n",
    "H4: ai_trust_to_adoption - ai_trust_not_to_adoption > 0 <br>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.0 Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ai_fairness_to_trust']].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary with mappings\n",
    "di_isnb = {5: 1, 4: 1, 3: 0, 2: 0, 1: 0}\n",
    "di_nonb = {5: 0, 4: 0, 3: 1, 2: 1, 1: 1}\n",
    "\n",
    "# create new dataframe that will be used\n",
    "df_new = df[['ai_fairness_to_trust']].copy()\n",
    "df_new.loc[:, 'isnb'] = df_new.loc[:, 'ai_fairness_to_trust']\n",
    "df_new.loc[:, 'nonb'] = df_new.loc[:, 'ai_fairness_to_trust']\n",
    "\n",
    "# code data\n",
    "df_new = df_new.replace({\"isnb\": di_isnb})\n",
    "df_new = df_new.replace({\"nonb\": di_nonb})\n",
    "\n",
    "# drop na\n",
    "df_new = df_new.dropna()\n",
    "\n",
    "# output data\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[['isnb']].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Computed the observed difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_diff = df_new['isnb'].sum() - df_new['nonb'].sum()\n",
    "print(obs_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Simulate the sampling distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sampling distribution of difference between number of wins by trained agent vs untrained agent\n",
    "diffs = []\n",
    "for _ in range(10000):\n",
    "    df_sample = df_new.sample(df_new.shape[0], replace = True)\n",
    "    sample_diff = df_sample['isnb'].sum() - df_sample['nonb'].sum()\n",
    "\n",
    "    diffs.append(sample_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "diffs = np.array(diffs)\n",
    "diffs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sampling distribution\n",
    "plt.hist(diffs);\n",
    "plt.axvline(x=obs_diff, color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 Simulate the distribution under the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate distribution under the null hypothesis\n",
    "null_vals = np.random.normal(0, diffs.std(), diffs.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot null distribution\n",
    "plt.hist(null_vals);\n",
    "\n",
    "# plot line for observed statistic\n",
    "plt.axvline(x=obs_diff, color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.4. Compute the p-value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute p value\n",
    "p_value = (null_vals > obs_diff).mean()\n",
    "print(p_value)\n",
    "if p_value > 0:\n",
    "    print('greater than 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if p_value < 0.01:\n",
    "    print('reject H0')\n",
    "else:\n",
    "    print('fail to reject H0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_corr = df.drop(['resp_id'], axis=1)\n",
    "df_corr.hist(figsize=(15, 40));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_ai = df[[\n",
    "                'ai_transparency_to_trust',\n",
    "                'ai_accountability_to_trust',\n",
    "                'ai_fairness_to_trust',\n",
    "                'ai_trust_to_adoption',\n",
    "                'ai_lack_trust_low_adoption',\n",
    "                'ai_must_be_trans_expl',\n",
    "                'ai_fat_to_trust'    \n",
    "                ]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "corr = df_ai.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=300),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_ai.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# function to create word cloud \n",
    "def create_wordcloud(df_cloud, i_column):\n",
    "    \"\"\" \n",
    "    creates a wordcload based on a dataframe column as input. \n",
    "\n",
    "    Parameters: \n",
    "    df_main (data frame): dataframe containing data\n",
    "    i_column (string): Column \n",
    "\n",
    "    Returns: \n",
    "    int: wordcloud\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "# get the text of what BIA tools are used\n",
    "    df_text = df_cloud.dropna(subset=[i_column]) \n",
    "    df_text = df_text[i_column]\n",
    "\n",
    "    # take dataframe and put in text\n",
    "    text = \" \".join(itext for itext in df_text)\n",
    "\n",
    "    stopwords = set(STOPWORDS)\n",
    "    stopwords.update([\"AI\", \"system\", \"organization\", 'application', 'one',  \"will\", \"need\", 'without', 'something', 'make',\n",
    "                       'based', 'stay', 'add', 'day', 'still'])\n",
    "\n",
    "    # Create and generate a word cloud image:\n",
    "    wordcloud = WordCloud(stopwords=stopwords, max_font_size=50, max_words=30, background_color=\"white\").generate(text)\n",
    "\n",
    "    # Display the generated image:\n",
    "    plt.figure(figsize=(30, 20))    \n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "create_wordcloud(df, 'ai_ethical_considerations')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "create_wordcloud(df, 'm_how_to_improve')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "create_wordcloud(df, 'mo_others')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "create_wordcloud(df, 'ms_what_doing_to_improve')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "create_wordcloud(df, 'ms_what_can_improve')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "create_wordcloud(df, 'what_would_prevent_usage')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_ai = df[[\n",
    "                'ai_transparency_to_trust',\n",
    "                'ai_accountability_to_trust',\n",
    "                'ai_fairness_to_trust',\n",
    "                'ai_trust_to_adoption',\n",
    "                'ai_lack_trust_low_adoption',\n",
    "                'ai_must_be_trans_expl',\n",
    "                'ai_fat_to_trust'    \n",
    "                ]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_ai.hist(figsize=(15, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# df.loc[:, ['Collector ID'] ]\n",
    "df.iloc[0:1, 110:] == 'Open-Ended Response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_q_feedback(icolumn, df_main):\n",
    "    \"\"\" \n",
    "    plot the data of a spesific dataframe columnn\n",
    "\n",
    "    prepare the data for plotting and plotting the datya \n",
    "\n",
    "    Parameters: \n",
    "    icolumn (string): the column that needs to be plotted\n",
    "    df_main (dataframe): the dataframe that is used\n",
    "\n",
    "    Returns: \n",
    "    a bar plotted\n",
    "\n",
    "    \"\"\"    \n",
    "    # prepare data    \n",
    "    quest_vals = df_main.groupby(icolumn)['Respondent ID'].nunique() # get unique value\n",
    "    quest_vals = quest_vals.to_frame()                               # convert to a dataframe\n",
    "    quest_vals['temp'] = quest_vals.index                            # prepare the table for display\n",
    "    quest_vals['code'] = quest_vals['temp'].map(codes_dict['Code'])  # prepare the table for display\n",
    "    quest_vals = quest_vals.sort_values(by=['code'])                 # sort the data for display\n",
    "        \n",
    "    # plot the figure\n",
    "    fig = plt.figure(figsize=(10, 3))\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    X = quest_vals.iloc[:,1]                       #very good, excelent etc\n",
    "    Y = quest_vals.iloc[:,0]\n",
    "    ax.bar(X,Y)\n",
    "    plt.title(df_columns[df_columns['Short Name'] == icolumn].index.tolist()[0]);\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# df[['Custom Data 1']]\n",
    "\n",
    "\n",
    "df['Custom Data 1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}